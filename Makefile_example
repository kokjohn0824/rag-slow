# Makefile for Prometheus ETL, training, and forecast exporter
# 本 Makefile 用於：
# - 執行 Prometheus/SNMP ETL（抽取/轉換/產出資料集）
# - 訓練 CPU/Memory/Disk 的 LSTM 預測模型
# - 啟動預測結果的 HTTP Exporter / PromQL-like API / 靜態前端
# - 透過 docker compose 管理 Prometheus 與 Forecast API 服務

# 可覆寫變數（範例：make train-cpu START=... END=...）
UV ?= uv
PY ?= python
RUN ?= $(UV) run $(PY)

# 設定檔路徑（Prometheus/SNMP/角色/管線）
PROM_CONF ?= configs/prometheus.yaml
SNMP_CONF ?= configs/snmp.yaml
ROLES_CONF ?= configs/roles.yaml
PIPELINE_CONF ?= configs/pipeline.yaml

# ETL / 訓練資料刷新用的時間範圍（ISO8601, Z=UTC）
START ?= 2025-11-10T00:00:00Z
END ?= 2025-12-10T00:00:00Z

# Exporter / API 設定
# - METRICS：要提供預測的指標集合（以逗號分隔）
# - PORT：服務埠
# - CACHE_TTL：快取有效秒數（降低重複計算/讀檔）
METRICS ?= cpu,memory,disk
PORT ?= 9108
CACHE_TTL ?= 60

# Docker Compose：主機端 models/outputs 目錄的映射來源（可替換）
# 預設在 ./docker 目錄執行 compose 時，對應到 repo 的 ../outputs
MODEL_DIR ?= ../outputs

# Docker build platform (for image save)
# - Default to linux/amd64; override ARCH=arm64 for linux/arm64
ARCH ?= amd64
PLATFORM ?= linux/$(ARCH)

# Remote deployment settings for SFTP
REMOTE_HOST ?= 192.168.4.208
REMOTE_USER ?= root
REMOTE_PATH ?= /root/test/images
REMOTE_OUTPUTS_PATH ?= /root/test/LSTM/outputs
REMOTE_COMPOSE_DIR ?= /root/test/LSTM
REMOTE_COMPOSE_FILE ?= docker-compose.yml
REMOTE_SERVICE_NAME ?= api

# Pooling（把多台 server 視為一個「合成節點」來訓練）的預設值
# - POOL_SERVERS：all 或 server 清單
# - POOL_METHOD：聚合方法（mean|median|sum）
# - POOL_ID：合成節點的識別名稱
POOL_SERVERS ?= all
POOL_METHOD ?= mean
POOL_ID ?= pooled

.PHONY: help install test etl exporter prometheus-up prometheus-down prometheus-logs \
	train-cpu train-cpu-pooled train-memory train-memory-pooled train-disk train-disk-pooled \
	train-disk-node03 train-cpu-node03 train-memory-node03 train-all train-all-pooled api ui \
	api-image-deploy outputs-deploy

help:
# 顯示可用指令與可覆寫變數
	@echo "Targets:"
	@echo "  install              - Create venv and install deps via uv"
	@echo "  test                 - Run pytest"
	@echo "  etl                  - Run ETL to build datasets (uses START/END)"
	@echo "  train-cpu            - Train LSTM for CPU (auto-selects ETL window)"
	@echo "  train-cpu-pooled     - Train CPU by pooling servers into one pseudo-node"
	@echo "  train-memory         - Train LSTM for Memory (auto-selects ETL window)"
	@echo "  train-memory-pooled  - Train Memory by pooling servers into one pseudo-node"
	@echo "  train-disk           - Train LSTM for Disk (auto-selects ETL window)"
	@echo "  train-disk-pooled    - Train Disk by pooling servers into one pseudo-node"
	@echo "  train-disk-node03    - Train Disk only for lia-rke2-node03 (no val)"
	@echo "  train-cpu-node03     - Train CPU only for lia-rke2-node03 (no val)"
	@echo "  train-memory-node03  - Train Memory only for lia-rke2-node03 (no val)"
	@echo "  train-all            - Train all three metrics"
	@echo "  train-all-pooled     - Train CPU/Memory/Disk with pooled servers"
	@echo "  exporter             - Start forecast HTTP exporter on PORT=$(PORT)"
	@echo "  api                  - Start PromQL-like forecast API on PORT=$(PORT)"
	@echo "  ui                   - Serve static frontend from ./frontend on PORT=$(PORT)"
	@echo "  prometheus-up        - Start Prometheus (docker compose)"
	@echo "  prometheus-down      - Stop Prometheus"
	@echo "  prometheus-logs      - Tail Prometheus logs"
	@echo "  api-up               - Start Forecast API (docker compose)"
	@echo "  api-down             - Stop Forecast API"
	@echo "  api-logs             - Tail Forecast API logs"
	@echo "  api-image-save       - Save Forecast API image as api-image-$(ARCH).tar (PLATFORM=$(PLATFORM))"
	@echo "  api-image-deploy     - Build, save API image and deploy to remote via SFTP"
	@echo "  outputs-deploy       - Deploy trained outputs/models via SFTP"
	@echo "Variables (override with VAR=value):"
	@echo "  For etl: START, END"
	@echo "  General: METRICS, PORT, CACHE_TTL, PROM_CONF, SNMP_CONF, ROLES_CONF, PIPELINE_CONF"
	@echo "  Pooling: POOL_SERVERS (all or list), POOL_METHOD (mean|median|sum), POOL_ID"
	@echo "  Deploy: REMOTE_HOST, REMOTE_USER, REMOTE_PATH, REMOTE_OUTPUTS_PATH, REMOTE_COMPOSE_DIR, REMOTE_COMPOSE_FILE, REMOTE_SERVICE_NAME"

install:
# 安裝相依：優先同步 dev group 與 extras；若失敗則退回一般 sync
	$(UV) sync --all-extras --group dev || $(UV) sync

test:
# 執行測試（pytest）
	$(UV) run pytest -q

etl:
# 執行 ETL：依設定檔與 START/END 從 Prometheus/SNMP 抽取並產出資料集
	$(RUN) main.py \
		--prometheus $(PROM_CONF) \
		--snmp $(SNMP_CONF) \
		--roles $(ROLES_CONF) \
		--pipeline $(PIPELINE_CONF) \
		--start $(START) \
		--end $(END)

train-cpu:
# 訓練 CPU 模型（LSTM）；--refresh 表示需要時會先刷新/重建資料
	$(RUN) scripts/train.py \
		--metric cpu --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--refresh

train-cpu-pooled:
# 訓練 CPU 模型（LSTM），但先把多台 server 聚合成一個合成節點（pooling）
	$(RUN) scripts/train.py \
		--metric cpu --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--pool-servers $(POOL_SERVERS) --pool-method $(POOL_METHOD) --pool-id $(POOL_ID) \
		--refresh

train-memory:
# 訓練 Memory 模型（LSTM）
	$(RUN) scripts/train.py \
		--metric memory --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--refresh

train-memory-pooled:
# 訓練 Memory 模型（LSTM）+ pooling（多台合成一台）
	$(RUN) scripts/train.py \
		--metric memory --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--pool-servers $(POOL_SERVERS) --pool-method $(POOL_METHOD) --pool-id $(POOL_ID) \
		--refresh

train-disk:
# 訓練 Disk 模型（LSTM）
	$(RUN) scripts/train.py \
		--metric disk --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--refresh

train-disk-pooled:
# 訓練 Disk 模型（LSTM）+ pooling（多台合成一台）
	$(RUN) scripts/train.py \
		--metric disk --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--pool-servers $(POOL_SERVERS) --pool-method $(POOL_METHOD) --pool-id $(POOL_ID) \
		--refresh

train-disk-node03:
# 只針對 lia-rke2-node03 訓練 Disk；--val-days 0 表示不切驗證集（常用於單點快速訓練）
	$(RUN) scripts/train.py \
		--metric disk --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--servers lia-rke2-node03 --val-days 0 \
		--refresh

train-cpu-node03:
# 只針對 lia-rke2-node03 訓練 CPU；不切驗證集
	$(RUN) scripts/train.py \
		--metric cpu --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--servers lia-rke2-node03 --val-days 0 \
		--refresh

train-memory-node03:
# 只針對 lia-rke2-node03 訓練 Memory；不切驗證集
	$(RUN) scripts/train.py \
		--metric memory --model lstm \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--servers lia-rke2-node03 --val-days 0 \
		--refresh

train-all: train-cpu train-memory train-disk
# 依序訓練 CPU/Memory/Disk（三個 target 的組合）

train-all-pooled: train-cpu-pooled train-memory-pooled train-disk-pooled
# 依序訓練 CPU/Memory/Disk（三個 pooled target 的組合）

exporter:
# 啟動「預測結果 exporter」HTTP 服務：
# - 讀取 outputs 中的訓練模型/資料窗
# - 提供對應 metrics 的預測輸出
	$(RUN) scripts/serve_forecast.py \
		--metrics $(METRICS) \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--outputs outputs \
		--port $(PORT) \
		--cache-ttl-seconds $(CACHE_TTL)

api:
# 啟動「PromQL-like forecast API」服務（通常給程式/前端查詢用）
	$(RUN) scripts/forecast_api.py \
		--prometheus $(PROM_CONF) --snmp $(SNMP_CONF) --roles $(ROLES_CONF) --pipeline $(PIPELINE_CONF) \
		--outputs outputs \
		--port $(PORT) \
		--cache-ttl-seconds $(CACHE_TTL)

ui:
# 用 Python 內建 http.server 提供 ./frontend 靜態站台
	$(RUN) -m http.server $(PORT) -d frontend

prometheus-up:
# 啟動 Prometheus（docker compose，背景模式）
	cd docker && docker compose up -d

prometheus-down:
# 停止並移除 Prometheus compose 資源
	cd docker && docker compose down

prometheus-logs:
# 追蹤 Prometheus logs（前景，持續輸出）
	cd docker && docker compose logs -f

# Docker Compose: API service
.PHONY: api-up api-down api-logs

api-up:
# 用 docker compose 啟動 Forecast API 服務（只啟動 api 這個 service）
# - API_PORT/CACHE_TTL/MODEL_DIR 透過環境變數傳入 compose
	cd docker && API_PORT=$(PORT) CACHE_TTL=$(CACHE_TTL) MODEL_DIR=$(MODEL_DIR) docker compose up -d api

api-down:
# 停止並移除 Forecast API container（保留其他 compose service）
	cd docker && docker compose stop api && docker compose rm -f api

api-logs:
# 追蹤 Forecast API logs（前景，持續輸出）
	cd docker && docker compose logs -f api

api-image-save:
# 建置指定平台 (預設 linux/amd64) 的 Forecast API image 並匯出成 tar 檔（方便離線部署/搬運）
	cd docker && docker buildx build --platform=$(PLATFORM) --load -t forecast-api:$(ARCH) -f Dockerfile.api .. && docker save forecast-api:$(ARCH) -o forecast-api-$(ARCH).tar

api-image-deploy:
# 建置 Forecast API image、匯出 tar 檔，並透過 SFTP 上傳到遠端主機
# 然後在遠端執行 docker load 和 docker compose restart
# 需求：ssh key 已設定（或手動輸入密碼）
	@echo "Building and saving API image for $(PLATFORM)..."
	cd docker && docker buildx build --platform=$(PLATFORM) --load -t forecast-api:$(ARCH) -f Dockerfile.api .. && docker save forecast-api:$(ARCH) -o forecast-api-$(ARCH).tar
	@echo "Deploying forecast-api-$(ARCH).tar to $(REMOTE_USER)@$(REMOTE_HOST):$(REMOTE_PATH)..."
	@echo "put docker/forecast-api-$(ARCH).tar $(REMOTE_PATH)" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "Loading Docker image on remote host..."
	ssh $(REMOTE_USER)@$(REMOTE_HOST) "docker load -i $(REMOTE_PATH)/forecast-api-$(ARCH).tar"
	@echo "Restarting Docker Compose service on remote host..."
	ssh $(REMOTE_USER)@$(REMOTE_HOST) "cd $(REMOTE_COMPOSE_DIR) && docker compose down && docker compose up -d "
	@echo "Deployment completed successfully!"
	@echo "  - Image: $(REMOTE_USER)@$(REMOTE_HOST):$(REMOTE_PATH)/forecast-api-$(ARCH).tar"
	@echo "  - Service: $(REMOTE_SERVICE_NAME) restarted in $(REMOTE_COMPOSE_DIR)/$(REMOTE_COMPOSE_FILE)"

outputs-deploy:
# 透過 SFTP 上傳訓練好的模型輸出（只同步 outputs/{cpu,memory,disk}/models）
# 需求：ssh key 已設定（或手動輸入密碼）
	@echo "Deploying outputs models to $(REMOTE_USER)@$(REMOTE_HOST):$(REMOTE_OUTPUTS_PATH)..."
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/cpu" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/memory" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/disk" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/cpu/models" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/memory/models" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "-mkdir $(REMOTE_OUTPUTS_PATH)/disk/models" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "put -r outputs/cpu/models $(REMOTE_OUTPUTS_PATH)/cpu" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "put -r outputs/memory/models $(REMOTE_OUTPUTS_PATH)/memory" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "put -r outputs/disk/models $(REMOTE_OUTPUTS_PATH)/disk" | sftp $(REMOTE_USER)@$(REMOTE_HOST)
	@echo "Outputs deployment completed successfully!"
